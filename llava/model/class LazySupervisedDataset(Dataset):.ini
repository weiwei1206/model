class LazySupervisedDataset(Dataset):
    """用于监督微调的数据集类。

    该类实现了懒加载策略，仅在需要时加载数据，以减少内存占用。
    """

    def __init__(self, data_path: str,
                 tokenizer: transformers.PreTrainedTokenizer,
                 data_args: DataArguments):
        """
        初始化 LazySupervisedDataset 实例。

        参数:
        data_path (str): 数据文件的路径，包含样本数据的 JSON 格式文件。
        tokenizer (transformers.PreTrainedTokenizer): 用于文本处理的分词器。
        data_args (DataArguments): 包含数据处理参数的对象，例如图像处理配置。
        """
        super(LazySupervisedDataset, self).__init__()
        list_data_dict = json.load(open(data_path, "r"))  # 从 JSON 文件加载数据

        rank0_print("Formatting inputs...Skip in lazy mode")  # 打印信息，指示输入格式化
        self.tokenizer = tokenizer  # 保存分词器
        self.list_data_dict = list_data_dict  # 保存加载的数据字典
        self.data_args = data_args  # 保存数据参数

    def __len__(self):
        """返回数据集中样本的数量。

        返回:
        int: 数据集中样本的数量。
        """
        return len(self.list_data_dict)

    @property
    def lengths(self):
        """计算每个样本的长度，考虑对话和图像的 token 数量。

        返回:
        List[int]: 每个样本的长度列表。
        """
        length_list = []
        for sample in self.list_data_dict:
            img_tokens = 128 if 'image' in sample else 0  # 如果样本包含图像，增加 token 数量
            length_list.append(sum(len(conv['value'].split()) for conv in sample['conversations']) + img_tokens)
        return length_list

    @property
    def modality_lengths(self):
        """计算每个样本的长度，图像的长度为负值，便于区分。

        返回:
        List[int]: 每个样本的长度列表，图像样本长度为负。
        """
        length_list = []
        for sample in self.list_data_dict:
            cur_len = sum(len(conv['value'].split()) for conv in sample['conversations'])
            cur_len = cur_len if 'image' in sample else -cur_len  # 图像样本长度为正，其它为负
            length_list.append(cur_len)
        return length_list

    def __getitem__(self, i) -> Dict[str, torch.Tensor]:
        """获取指定索引的样本数据。

        参数:
        i (int): 样本的索引。

        返回:
        Dict[str, torch.Tensor]: 包含输入 ID、标签和图像数据的字典。
        """
        sources = self.list_data_dict[i]  # 获取指定索引的样本
        if isinstance(i, int):
            sources = [sources]  # 确保 sources 是列表
        assert len(sources) == 1, "Don't know why it is wrapped to a list"  # 确保只有一个样本

        # 如果样本包含图像，则处理图像
        if 'image' in sources[0]:
            image_file = self.list_data_dict[i]['image']  # 获取图像文件名
            image_folder = self.data_args.image_folder  # 获取图像文件夹路径
            processor = self.data_args.image_processor  # 获取图像处理器
            image = Image.open(os.path.join(image_folder, image_file)).convert('RGB')  # 打开图像并转换为 RGB 模式

            # 根据配置调整图像的长宽比
            if self.data_args.image_aspect_ratio == 'pad':
                def expand2square(pil_img, background_color):
                    width, height = pil_img.size
                    if width == height:
                        return pil_img
                    elif width > height:
                        result = Image.new(pil_img.mode, (width, width), background_color)
                        result.paste(pil_img, (0, (width - height) // 2))
                        return result
                    else:
                        result = Image.new(pil_img.mode, (height, height), background_color)
                        result.paste(pil_img, ((height - width) // 2, 0))
                        return result
                
                image = expand2square(image, tuple(int(x*255) for x in processor.image_mean))  # 调整图像为正方形
                image = processor.preprocess(image, return_tensors='pt')['pixel_values'][0]  # 预处理图像
            else:
                image = processor.preprocess(image, return_tensors='pt')['pixel_values'][0]  # 预处理图像

            # 处理多模态数据
            sources = preprocess_multimodal(
                copy.deepcopy([e["conversations"] for e in sources]),
                self.data_args)
        else:
            sources = copy.deepcopy([e["conversations"] for e in sources])  # 仅处理对话数据

        # 预处理文本数据
        data_dict = preprocess(
            sources,
            self.tokenizer,
            has_image=('image' in self.list_data_dict[i]))  # 判断是否包含图像

        if isinstance(i, int):
            data_dict = dict(input_ids=data_dict["input_ids"][0],
                             labels=data_dict["labels"][0])  # 提取单个样本的输入 ID 和标签

        # 如果样本包含图像，则将图像添加到数据字典中
        if 'image' in self.list_data_dict[i]:
            data_dict['image'] = image
        elif self.data_args.is_multimodal:
            # 如果样本不包含图像，但模型为多模态，则创建一个空的图像张量
            crop_size = self.data_args.image_processor.crop_size
            data_dict['image'] = torch.zeros(3, crop_size['height'], crop_size['width'])

        return data_dict  # 返回整理好的数据字典
